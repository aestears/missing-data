---
title: "Missing data summary"
author: "Matt T"
date:  "`r Sys.Date()`"
output:
  
  html_document: default
  pdf_document: default
--- 
```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(dplyr)
library(shinystan)
library(faux)
library(bayesplot)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(lubridate)
library(data.table)
library(Amelia)
library(tidyr)
library(MASS)
library(plyr)
library(ggplot2)
library(summarytools)
library(knitr)
library(abind)

options(scipen=999)

#setwd("C:/Users/mtrentman/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions")
setwd("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions")
#setwd("~/GitHub/missing-data")
sp<-read.csv('daily.predictions.filled.csv',header = TRUE) ##Missing dates filled in
sp$date.f<-as.Date(sp$date.f,format="%Y-%m-%d")
sp$site_name<-as.character(sp$site_name)
#sp<-read.table(file = 'daily_predictions.tsv',header = TRUE) ##Raw data
sd<-read.table(file = 'site_data.tsv',header = TRUE)##Site data
sd$site_name<-as.character(sd$site_name)

##Function to switch font color depending on the output (HTML or PDF)
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, 
      x)
  } else x
}

```
### Model
Then used an AR(1) missing data process-model with an intercept and light covariate to model the parameters and missing data.
$$
GPP=\beta_0+\phi\times GPP_{t-1}+\beta_1\times X_{light}+\epsilon_{sdp}
$$
\
\
\
\
\
\

### Stan Code
```{r,eval=FALSE}
"
 
/*----------------------- Data --------------------------*/
  /* Data block: defines the objects that will be inputted as data */
  data {
    int N; // Length of state and observation time series
    vector[N] y_miss; // Observations
    real z0; // Initial state value
    vector[N] light; //log of light observations
    int y_nMiss; // number of missing values
    int y_index_mis[y_nMiss]; // index or location of missing values within the dataset
  }
  
  
  
/*----------------------- Parameters --------------------------*/
  /* Parameter block: defines the variables that will be sampled */
  parameters {
    vector<lower = 0>[y_nMiss] y_imp;// Missing data
    real<lower=0> sdp; // Standard deviation of the process equation
    real b0;
    real b1;
    real<lower = 0, upper=1 > phi; // Auto-regressive parameter
   
  }
  transformed parameters { 
    vector[N] y;
    y=y_miss; // makes the data a transformed variable
    y[y_index_mis] =y_imp; // replaces missing data in y with estimated data
  } 
    
    
    
  /*----------------------- Model --------------------------*/
  /* Model block: defines the model */
  model {
    // Prior distributions
    sdp ~ normal(0, 1);
    phi ~ beta(1,1);
    b0 ~ normal(0,5);
    b1 ~ normal(0,5);
    
    // Distribution for the first value
    y[1] ~ normal(z0, sdp);
   
    // Distributions for all other states
    for(t in 2:N){
      y[t] ~ normal(b0+y[t-1]*phi+light[t]*b1, sdp);
    }
    
    
  /*----------------------- Generated Quantities --------------------------*/
  /*Generated Quantities block: genereate things, such as modeled estimates for PPC */
   generated quantities {
    vector[N] y_rep; // replications from posterior predictive dist
    y_rep[1]=normal_rng(y[1], 0.1);
 
    for (t in 2:N) {
    y_rep[t]=normal_rng(b0+y[t-1]*phi+light[t]*b1, sdp);
 }
  }
"
```


### Simulated-randomly missing days-high error and phi
$$
GPP=\beta_0+\phi\times GPP_{t-1}+\beta_1\times X_{light}+\epsilon_{sdp}
$$
$\beta_0$=0.1\
$\epsilon_{sdp}$= 0.1\
$\phi$=0.8\
$\beta_1$=0.1\
$X_{light}$=modeled from Yard et al. (1995) Ecological Modeling\


``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}
## Simulated Data
###Simulate data
N<-365 #length of data
t<-1:N #time
time<-seq(as.POSIXct("2020/1/1"),as.POSIXct("2020/12/30"), by="day") #for light

##light
# From Yard et al. (1995) Ecological Modelling.  Remember your trig?  
# calculate light as umol photon m-2 s-1.
# Arguments are:  
# time = a date and time input (posixct object)
# lat = latitude of field site
# longobs = longitude of field site
# longstd = standard longitude of the field site (NOTE: watch daylight savings time!!!). For PST, longstd is be 120 degrees. But during PDT it is 105 degrees. MST is 105 deg. MDT is 90. 


# convert degrees to radians
radi<-function(degrees){(degrees*pi/180)}

# function to estimate light
lightest<- function (time, lat, longobs, longstd) {
  jday<-yday(time)
  E<- 9.87*sin(radi((720*(jday-81))/365)) - 7.53*cos(radi((360*(jday-81))/365)) - 1.5*sin(radi((360*(jday-81))/365))
  LST<-as.numeric(time-trunc(time))
  ST<-LST+(3.989/1440)*(longstd-longobs)+E/1440
  solardel<- 23.439*sin(radi(360*((283+jday)/365)))
  hourangle<-(0.5-ST)*360
  theta<- acos( sin(radi(solardel)) * sin(radi(lat)) + cos(radi(solardel)) * cos(radi(lat)) * cos(radi(hourangle)) )
  suncos<-ifelse(cos(theta)<0, 0, cos(theta))
  GI<- suncos*2326
  GI	
  
}
light<-lightest(time, 47.8762, -114.03, 105) #Flathead Bio Station just for fun
light.l<-log(light)
light.c<-(light-mean(light))/sd(light)



##GPP based on time-series model with known paramters
set.seed(553)
x<-NA
sdp <- 0.1
phi <-0.8
b0<-0.1
b1<-0.1
x[1]<-3.5
# Set the seed, so we can reproduce the results
set.seed(553)
# For-loop that simulates the state through time, using i instead of t,
for (t in 2:N){
  x[t] = b0+phi*x[t-1]+light.l[t]*b1+rnorm(1, 0, sdp)
}


y_full<-as.data.frame(cbind(x,time))

ggplot(data=y_full, aes(x=time, y=x))+
  geom_point(color="black", size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time (days)")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  ggtitle("Full dataset")

##Force some missing data-BY DAY##
#Note-the model will still work if no data is missing but the objects in the next block of code (i.e., "y_index_mis", etc.)
#still need to be created

set.seed(90)
y_miss<-list(x,x,x,x,x,x,x,x)

#vector of missing number amounts
missing_n<-c(0,round(N*0.15),round(N*0.3),round(N*0.4),round(N*0.5),round(N*0.6),round(N*0.7),round(N*0.8))
#Create a list to store missing data integers
y_missing_integers<-c()
#Create a vector of the length of data representing the indexes
index<-c()
index[[1]]<-1:N

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-sample(index,missing_n[1],replace = FALSE)
#index<-index[-y_missing_integers[[1]]]

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n)){
 h<-sample(index[[i-1]],(missing_n[i]-missing_n[i-1]), replace = FALSE)
 index[[i]]<-setdiff(index[[i-1]],h)
 y_missing_integers[[i]]<-unlist(c(h,y_missing_integers[[i-1]]))
}

#Assign NAs to the missing data in each list
for(i in 2:length(missing_n)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  z[1]<-x[1]
  y_miss[[i]]<-z
}

#Check that each list has the right amount of missing data (or close to it...)
miss<-sapply(y_miss, function(x) sum(length(which(is.na(x)))))
prop.miss<-round(miss/length(x)*100)
#prop.miss

y_reduced<-as.data.frame(cbind(y_miss[[6]],time))

ggplot(data=y_reduced, aes(x=time, y=V1))+
  geom_point(color="black", size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time (days)")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  ggtitle("Reduced dataset (60% removed)")

```
\
\
\
\
\

### Bayes estimated missing data-simulated missing days-high sdp and phi
``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}
fit.miss<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/full_sim_day_bayes_sdp_1_phi_8.RDS")
fit_summary<-summary(fit.miss[[6]], probs=c(0.025,.5,.975))$summary

###Simulate data
N<-365 #length of data
t<-1:N #time
time<-seq(as.POSIXct("2020/1/1"),as.POSIXct("2020/12/30"), by="day") #for light

##light
# From Yard et al. (1995) Ecological Modelling.  Remember your trig?  
# calculate light as umol photon m-2 s-1.
# Arguments are:  
# time = a date and time input (posixct object)
# lat = latitude of field site
# longobs = longitude of field site
# longstd = standard longitude of the field site (NOTE: watch daylight savings time!!!). For PST, longstd is be 120 degrees. But during PDT it is 105 degrees. MST is 105 deg. MDT is 90. 


# convert degrees to radians
radi<-function(degrees){(degrees*pi/180)}

# function to estimate light
lightest<- function (time, lat, longobs, longstd) {
  jday<-yday(time)
  E<- 9.87*sin(radi((720*(jday-81))/365)) - 7.53*cos(radi((360*(jday-81))/365)) - 1.5*sin(radi((360*(jday-81))/365))
  LST<-as.numeric(time-trunc(time))
  ST<-LST+(3.989/1440)*(longstd-longobs)+E/1440
  solardel<- 23.439*sin(radi(360*((283+jday)/365)))
  hourangle<-(0.5-ST)*360
  theta<- acos( sin(radi(solardel)) * sin(radi(lat)) + cos(radi(solardel)) * cos(radi(lat)) * cos(radi(hourangle)) )
  suncos<-ifelse(cos(theta)<0, 0, cos(theta))
  GI<- suncos*2326
  GI	
  
}
light<-lightest(time, 47.8762, -114.03, 105) #Flathead Bio Station just for fun
light.l<-log(light)
light.c<-(light-mean(light))/sd(light)


##GPP based on time-series model with known paramters
set.seed(553)
x<-NA
sdp <- 0.1
phi <-0.8
b0<-0.1
b1<-0.1
x[1]<-3.5
# Set the seed, so we can reproduce the results
set.seed(553)
# For-loop that simulates the state through time, using i instead of t,
for (t in 2:N){
  x[t] = b0+phi*x[t-1]+light.l[t]*b1+rnorm(1, 0, sdp)
}


set.seed(90)
y_miss<-list(x,x,x,x,x,x,x,x)

#vector of missing number amounts
missing_n<-c(0,round(N*0.15),round(N*0.3),round(N*0.4),round(N*0.5),round(N*0.6),round(N*0.7),round(N*0.8))
#Create a list to store missing data integers
y_missing_integers<-c()
#Create a vector of the length of data representing the indexes
index<-c()
index[[1]]<-1:N

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-sample(index,missing_n[1],replace = FALSE)
#index<-index[-y_missing_integers[[1]]]

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n)){
 h<-sample(index[[i-1]],(missing_n[i]-missing_n[i-1]), replace = FALSE)
 index[[i]]<-setdiff(index[[i-1]],h)
 y_missing_integers[[i]]<-unlist(c(h,y_missing_integers[[i-1]]))
}

#Assign NAs to the missing data in each list
for(i in 2:length(missing_n)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  z[1]<-x[1]
  y_miss[[i]]<-z
}

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR LIST OF VECTORS
y_index_mis <- lapply(y_miss,function(var){which(is.na(var))}) # Identify the rows for each variable in airquality with NA
y_index_obs <- lapply(y_miss,function(var){which(!is.na(var))}) # Identify the rows for each variable in airquality with observed data
y_nMiss <- lapply(y_index_mis,function(var){length(var)}) # How many NAs?
y_nObs <- lapply(y_index_obs,function(var){length(var)}) # How many NAs?

my_data <- as_tibble(fit_summary)
y_est_data<-my_data %>% slice(1:length(y_index_mis[[6]]))

##Create object with observed data
date<-1:N
y_obs_data<-as.data.frame(cbind(date[y_index_mis[[6]]],x[y_index_mis[[6]]]))
colnames(y_obs_data)<-c("date","y")
#y_obs_data$date<-as.Date(y_obs_data$date, origin = "1969-12-30")
#x_data<-summary(fit_extract$x, probs=c(0.05,.5,.95))
##Merge observed and estimated

y_combined<-cbind(y_obs_data,y_est_data)

##rename column names for clarity

colnames(y_combined)<-c("date", "observed", "estimated", "se_mean_est", "sd_est", "low", "median","high", "n_eff", "rhat")

##check that column names are correct



##Plot observed and estimated direct comparison
ggplot(data=y_combined, aes(x=observed, y=estimated))+
  geom_point( size=3)+
  geom_abline(intercept=0, slope=1)+
  theme_classic()+
  geom_errorbar(aes(ymin=low, ymax=high))+
  theme(legend.position="top")+
  ylab("Estimated GPP (95% CI)")+
  xlab("Simulated GPP")+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))

##Plot observed and estimated as time series
raw_data<-as.data.frame(cbind(x,date))

ggplot(data=y_combined, aes(x=date, y=estimated))+
  geom_point(data=raw_data, aes(x=date, y=x, color="gray"), size=3)+
  geom_errorbar(data=y_combined,aes(x=date,ymin=low, ymax=high))+ 
  geom_point(aes(color="red"), size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  scale_color_identity(guide = "legend", name=element_blank(), labels=c("Simulated data", "Imputed data"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())



```


\
\
\
\
\

### Bayes parameter-simulated missing days
``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}

fit_sim_summary_bayes <- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/summary_sim_day_bayes_sdp_1_phi_8.RDS")
known.data.sim<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/known_sim_day_bayes_sdp_1_phi_8.RDS")


ggplot(data=fit_sim_summary_bayes, aes(x=mean, y=prop.missing ))+
  geom_point(aes( color=param, group=param),size=3,position=position_dodge(0.5))+
  theme_classic()+
  geom_errorbar(aes(xmin=min, xmax=high,color=param, group=param), width=0.2, size=0.5,position=position_dodge(0.5))+
  theme(legend.position="top")+
  ylab("Percent of Missing Data")+
  xlab("Parameter Estimate")+
  scale_color_manual(values=c("blue", "green", "darkgray", "black"))+
  scale_x_continuous(limits=c(-.2,0.9))+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  geom_vline(xintercept = known.data.sim$known.data,color=c("blue", "darkgray", "green", "black"))

```
\
\
\
\
\
\

### Simulated-randomly missing days-lower error and phi
$$
GPP=\beta_0+\phi\times GPP_{t-1}+\beta_1\times X_{light}+\epsilon_{sdp}
$$
$\beta_0$=0.1\
$\epsilon_{sdp}$= 0.01\
$\phi$=0.5\
$\beta_1$=0.1\
$X_{light}$=modeled from Yard et al. (1995) Ecological Modeling\


``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}
## Simulated Data
###Simulate data
N<-365 #length of data
t<-1:N #time
time<-seq(as.POSIXct("2020/1/1"),as.POSIXct("2020/12/30"), by="day") #for light

##light
# From Yard et al. (1995) Ecological Modelling.  Remember your trig?  
# calculate light as umol photon m-2 s-1.
# Arguments are:  
# time = a date and time input (posixct object)
# lat = latitude of field site
# longobs = longitude of field site
# longstd = standard longitude of the field site (NOTE: watch daylight savings time!!!). For PST, longstd is be 120 degrees. But during PDT it is 105 degrees. MST is 105 deg. MDT is 90. 


# convert degrees to radians
radi<-function(degrees){(degrees*pi/180)}

# function to estimate light
lightest<- function (time, lat, longobs, longstd) {
  jday<-yday(time)
  E<- 9.87*sin(radi((720*(jday-81))/365)) - 7.53*cos(radi((360*(jday-81))/365)) - 1.5*sin(radi((360*(jday-81))/365))
  LST<-as.numeric(time-trunc(time))
  ST<-LST+(3.989/1440)*(longstd-longobs)+E/1440
  solardel<- 23.439*sin(radi(360*((283+jday)/365)))
  hourangle<-(0.5-ST)*360
  theta<- acos( sin(radi(solardel)) * sin(radi(lat)) + cos(radi(solardel)) * cos(radi(lat)) * cos(radi(hourangle)) )
  suncos<-ifelse(cos(theta)<0, 0, cos(theta))
  GI<- suncos*2326
  GI	
  
}
light<-lightest(time, 47.8762, -114.03, 105) #Flathead Bio Station just for fun
light.l<-log(light)
light.c<-(light-mean(light))/sd(light)



##GPP based on time-series model with known paramters
set.seed(553)
x<-NA
sdp <- 0.01
phi <-0.5
b0<-0.1
b1<-0.1
x[1]<-1.5
# Set the seed, so we can reproduce the results
set.seed(553)
# For-loop that simulates the state through time, using i instead of t,
for (t in 2:N){
  x[t] = b0+phi*x[t-1]+light.l[t]*b1+rnorm(1, 0, sdp)
}


y_full<-as.data.frame(cbind(x,time))

ggplot(data=y_full, aes(x=time, y=x))+
  geom_point(color="black", size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time (days)")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  ggtitle("Full dataset")

##Force some missing data-BY DAY##
#Note-the model will still work if no data is missing but the objects in the next block of code (i.e., "y_index_mis", etc.)
#still need to be created

set.seed(90)
#Store simulated data in a list 
y_miss<-list(x,x,x,x,x,x,x,x)

#vector of missing number amounts
missing_n<-c(0,round(N*0.15),round(N*0.3),round(N*0.4),round(N*0.5),round(N*0.6),round(N*0.7),round(N*0.8))
#Create a list to store missing data integers
y_missing_integers<-c()
#Create a vector of the length of data representing the indexes
index<-c()
index[[1]]<-1:N

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-sample(index,missing_n[1],replace = FALSE)
#index<-index[-y_missing_integers[[1]]]

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n)){
 h<-sample(index[[i-1]],(missing_n[i]-missing_n[i-1]), replace = FALSE)
 index[[i]]<-setdiff(index[[i-1]],h)
 y_missing_integers[[i]]<-unlist(c(h,y_missing_integers[[i-1]]))
}

#Assign NAs to the missing data in each list
for(i in 2:length(missing_n)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  z[1]<-x[1]
  y_miss[[i]]<-z
}

#Check that each list has the right amount of missing data (or close to it...)
miss<-sapply(y_miss, function(x) sum(length(which(is.na(x)))))
prop.miss<-round(miss/length(x)*100)
#prop.miss

y_reduced<-as.data.frame(cbind(y_miss[[6]],time))

ggplot(data=y_reduced, aes(x=time, y=V1))+
  geom_point(color="black", size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time (days)")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  ggtitle("Reduced dataset (60% removed)")

```
\
\
\
\
\
\
\

### Bayes estimated missing data-simulated missing days-low sdp and phi
``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}
fit.miss<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/full_sim_day_bayes_sdp_01_phi_5.RDS")
fit_summary<-summary(fit.miss[[6]], probs=c(0.025,.5,.975))$summary

###Simulate data
N<-365 #length of data
t<-1:N #time
time<-seq(as.POSIXct("2020/1/1"),as.POSIXct("2020/12/30"), by="day") #for light

##light
# From Yard et al. (1995) Ecological Modelling.  Remember your trig?  
# calculate light as umol photon m-2 s-1.
# Arguments are:  
# time = a date and time input (posixct object)
# lat = latitude of field site
# longobs = longitude of field site
# longstd = standard longitude of the field site (NOTE: watch daylight savings time!!!). For PST, longstd is be 120 degrees. But during PDT it is 105 degrees. MST is 105 deg. MDT is 90. 


# convert degrees to radians
radi<-function(degrees){(degrees*pi/180)}

# function to estimate light
lightest<- function (time, lat, longobs, longstd) {
  jday<-yday(time)
  E<- 9.87*sin(radi((720*(jday-81))/365)) - 7.53*cos(radi((360*(jday-81))/365)) - 1.5*sin(radi((360*(jday-81))/365))
  LST<-as.numeric(time-trunc(time))
  ST<-LST+(3.989/1440)*(longstd-longobs)+E/1440
  solardel<- 23.439*sin(radi(360*((283+jday)/365)))
  hourangle<-(0.5-ST)*360
  theta<- acos( sin(radi(solardel)) * sin(radi(lat)) + cos(radi(solardel)) * cos(radi(lat)) * cos(radi(hourangle)) )
  suncos<-ifelse(cos(theta)<0, 0, cos(theta))
  GI<- suncos*2326
  GI	
  
}
light<-lightest(time, 47.8762, -114.03, 105) #Flathead Bio Station just for fun
light.l<-log(light)
light.c<-(light-mean(light))/sd(light)


##GPP based on time-series model with known paramters
set.seed(553)
x<-NA
sdp <- 0.01
phi <-0.5
b0<-0.1
b1<-0.1
x[1]<-1.5
# Set the seed, so we can reproduce the results
set.seed(553)
# For-loop that simulates the state through time, using i instead of t,
for (t in 2:N){
  x[t] = b0+phi*x[t-1]+light.l[t]*b1+rnorm(1, 0, sdp)
}


set.seed(90)
#Store simulated data in a list 
y_miss<-list(x,x,x,x,x,x,x,x)

#vector of missing number amounts
missing_n<-c(0,round(N*0.15),round(N*0.3),round(N*0.4),round(N*0.5),round(N*0.6),round(N*0.7),round(N*0.8))
#Create a list to store missing data integers
y_missing_integers<-c()
#Create a vector of the length of data representing the indexes
index<-c()
index[[1]]<-1:N

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-sample(index,missing_n[1],replace = FALSE)
#index<-index[-y_missing_integers[[1]]]

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n)){
 h<-sample(index[[i-1]],(missing_n[i]-missing_n[i-1]), replace = FALSE)
 index[[i]]<-setdiff(index[[i-1]],h)
 y_missing_integers[[i]]<-unlist(c(h,y_missing_integers[[i-1]]))
}

#Assign NAs to the missing data in each list
for(i in 2:length(missing_n)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  z[1]<-x[1]
  y_miss[[i]]<-z
}


##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR LIST OF VECTORS
y_index_mis <- lapply(y_miss,function(var){which(is.na(var))}) # Identify the rows for each variable in airquality with NA
y_index_obs <- lapply(y_miss,function(var){which(!is.na(var))}) # Identify the rows for each variable in airquality with observed data
y_nMiss <- lapply(y_index_mis,function(var){length(var)}) # How many NAs?
y_nObs <- lapply(y_index_obs,function(var){length(var)}) # How many NAs?

my_data <- as_tibble(fit_summary)
y_est_data<-my_data %>% slice(1:length(y_index_mis[[6]]))

##Create object with observed data
date<-1:N
y_obs_data<-as.data.frame(cbind(date[y_index_mis[[6]]],x[y_index_mis[[6]]]))
colnames(y_obs_data)<-c("date","y")
#y_obs_data$date<-as.Date(y_obs_data$date, origin = "1969-12-30")
#x_data<-summary(fit_extract$x, probs=c(0.05,.5,.95))
##Merge observed and estimated

y_combined<-cbind(y_obs_data,y_est_data)

##rename column names for clarity

colnames(y_combined)<-c("date", "observed", "estimated", "se_mean_est", "sd_est", "low", "median","high", "n_eff", "rhat")

##check that column names are correct



##Plot observed and estimated direct comparison
ggplot(data=y_combined, aes(x=observed, y=estimated))+
  geom_point( size=3)+
  geom_abline(intercept=0, slope=1)+
  theme_classic()+
  geom_errorbar(aes(ymin=low, ymax=high))+
  theme(legend.position="top")+
  ylab("Estimated GPP (95% CI)")+
  xlab("Simulated GPP")+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))

##Plot observed and estimated as time series
raw_data<-as.data.frame(cbind(x,date))

ggplot(data=y_combined, aes(x=date, y=estimated))+
  geom_point(data=raw_data, aes(x=date, y=x, color="gray"), size=3)+
  geom_errorbar(data=y_combined,aes(x=date,ymin=low, ymax=high))+ 
  geom_point(aes(color="red"), size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  scale_color_identity(guide = "legend", name=element_blank(), labels=c("Simulated data", "Imputed data"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())



```
\
\
\
\
\
\
\

### Bayes parameter-simulated missing days-low sdp and phi
``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}

fit_sim_summary_bayes <- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/summary_sim_day_bayes_sdp_01_phi_5.RDS")
known.data.sim<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/known_sim_day_bayes_sdp_01_phi_5.RDS")


ggplot(data=fit_sim_summary_bayes, aes(x=mean, y=prop.missing ))+
  geom_point(aes( color=param, group=param),size=3,position=position_dodge(0.5))+
  theme_classic()+
  geom_errorbar(aes(xmin=min, xmax=high,color=param, group=param), width=0.2, size=0.5,position=position_dodge(0.5))+
  theme(legend.position="top")+
  ylab("Percent of Missing Data")+
  xlab("Parameter Estimate")+
  scale_color_manual(values=c("blue", "green", "darkgray", "black"))+
  scale_x_continuous(limits=c(-.1,0.9))+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  geom_vline(xintercept = known.data.sim$known.data,color=c("black", "darkgray", "green", "blue"))

```
\
\
\
\
\
\
\



### Simulated-randomly missing weeks
```{r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}
N<-365 #length of data
t<-1:N #time
time<-seq(as.POSIXct("2020/1/1"),as.POSIXct("2020/12/30"), by="day") #for light

##light
# From Yard et al. (1995) Ecological Modelling.  Remember your trig?  
# calculate light as umol photon m-2 s-1.
# Arguments are:  
# time = a date and time input (posixct object)
# lat = latitude of field site
# longobs = longitude of field site
# longstd = standard longitude of the field site (NOTE: watch daylight savings time!!!). For PST, longstd is be 120 degrees. But during PDT it is 105 degrees. MST is 105 deg. MDT is 90. 


# convert degrees to radians
radi<-function(degrees){(degrees*pi/180)}

# function to estimate light
lightest<- function (time, lat, longobs, longstd) {
  jday<-yday(time)
  E<- 9.87*sin(radi((720*(jday-81))/365)) - 7.53*cos(radi((360*(jday-81))/365)) - 1.5*sin(radi((360*(jday-81))/365))
  LST<-as.numeric(time-trunc(time))
  ST<-LST+(3.989/1440)*(longstd-longobs)+E/1440
  solardel<- 23.439*sin(radi(360*((283+jday)/365)))
  hourangle<-(0.5-ST)*360
  theta<- acos( sin(radi(solardel)) * sin(radi(lat)) + cos(radi(solardel)) * cos(radi(lat)) * cos(radi(hourangle)) )
  suncos<-ifelse(cos(theta)<0, 0, cos(theta))
  GI<- suncos*2326
  GI	
  
}
light<-lightest(time, 47.8762, -114.03, 105) #Flathead Bio Station just for fun
light.l<-log(light)
light.c<-(light-mean(light))/sd(light)



##GPP based on time-series model with known paramters
set.seed(553)
x<-NA
sdp <- 0.1
phi <-0.8
b0<-0.1
b1<-0.1
x[1]<-3.5
# Set the seed, so we can reproduce the results
set.seed(553)
# For-loop that simulates the state through time, using i instead of t,
for (t in 2:N){
  x[t] = b0+phi*x[t-1]+light.l[t]*b1+rnorm(1, 0, sdp)
}

y_full<-as.data.frame(cbind(x,time))

ggplot(data=y_full, aes(x=time, y=x))+
  geom_point(color="black", size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time (days)")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  ggtitle("Full dataset")


set.seed(50)

y_miss<-list(x,x,x,x,x,x)
#vector of missing number amounts
missing_n_tot<-c(0,25,50,100,150,300)

missing_n_week<-round(missing_n_tot/7)

#Create a list to store missing data integers
y_missing_integers<-c()

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-which(is.na(y_miss[[1]]))

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n_week)){
  h<-which(x %in% sample(x,(missing_n_week[i]-missing_n_week[i-1]), replace = FALSE))
  y_missing_integers[[i]]<-c(h,y_missing_integers[[i-1]])
}


for(i in 2:length(missing_n_week)){
  q<-y_missing_integers[[i]]-3
  w<-y_missing_integers[[i]]-2
  e<-y_missing_integers[[i]]-1
  t<-y_missing_integers[[i]]+1
  y<-y_missing_integers[[i]]+2
  u<-y_missing_integers[[i]]+3
  y_missing_integers[[i]]<-c(y_missing_integers[[i]],q,w,e,t,y,u)
}

##Remove last value from indexes 6-8. Unique to this random seed and weeks.
#Accidentally added a missing value to the end because it picked a value close to the end



#Assign NAs to the missing data in each list
for(i in 1:length(y_missing_integers)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  #z[1]<-x[1]
  y_miss[[i]]<-z
}

y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]



miss<-sapply(y_miss, function(x) sum(length(which(is.na(x)))))
prop.miss<-round(miss/length(x)*100)


##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR SINGLE VECTOR
#y_index_mis <- which(is.na(y_miss)) # Identify the rows for each variable in airquality with NA
#y_index_obs <- which(!is.na(y_miss)) # Identify the rows for each variable in airquality with observed data
#y_nMiss <- length(y_index_mis)# How many NAs?
#y_nObs <- length(y_index_obs) # How many NAs?

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR LIST OF VECTORS
y_index_mis <- lapply(y_miss,function(var){which(is.na(var))}) # Identify the rows for each variable in airquality with NA
y_index_obs <- lapply(y_miss,function(var){which(!is.na(var))}) # Identify the rows for each variable in airquality with observed data
y_nMiss <- lapply(y_index_mis,function(var){length(var)}) # How many NAs?
y_nObs <- lapply(y_index_obs,function(var){length(var)}) # How many NAs?



#y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]

y_reduced<-as.data.frame(cbind(y_miss[[6]],time))

ggplot(data=y_reduced, aes(x=time, y=V1))+
  geom_point(color="black", size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time (days)")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  ggtitle("Reduced dataset (60% removed)")


```
\
\
\
\
\
\

### Bayes estimated missing data simulated missing weeks-higher sdp and phi
``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}
fit.miss<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/full_sim_week_bayes.RDS")
fit_summary<-summary(fit.miss[[6]], probs=c(0.025,.5,.975))$summary


N<-365 #length of data
t<-1:N #time
time<-seq(as.POSIXct("2020/1/1"),as.POSIXct("2020/12/30"), by="day") #for light

##light
# From Yard et al. (1995) Ecological Modelling.  Remember your trig?  
# calculate light as umol photon m-2 s-1.
# Arguments are:  
# time = a date and time input (posixct object)
# lat = latitude of field site
# longobs = longitude of field site
# longstd = standard longitude of the field site (NOTE: watch daylight savings time!!!). For PST, longstd is be 120 degrees. But during PDT it is 105 degrees. MST is 105 deg. MDT is 90. 


# convert degrees to radians
radi<-function(degrees){(degrees*pi/180)}

# function to estimate light
lightest<- function (time, lat, longobs, longstd) {
  jday<-yday(time)
  E<- 9.87*sin(radi((720*(jday-81))/365)) - 7.53*cos(radi((360*(jday-81))/365)) - 1.5*sin(radi((360*(jday-81))/365))
  LST<-as.numeric(time-trunc(time))
  ST<-LST+(3.989/1440)*(longstd-longobs)+E/1440
  solardel<- 23.439*sin(radi(360*((283+jday)/365)))
  hourangle<-(0.5-ST)*360
  theta<- acos( sin(radi(solardel)) * sin(radi(lat)) + cos(radi(solardel)) * cos(radi(lat)) * cos(radi(hourangle)) )
  suncos<-ifelse(cos(theta)<0, 0, cos(theta))
  GI<- suncos*2326
  GI	
  
}
light<-lightest(time, 47.8762, -114.03, 105) #Flathead Bio Station just for fun
light.l<-log(light)
light.c<-(light-mean(light))/sd(light)



##GPP based on time-series model with known paramters
set.seed(553)
x<-NA
sdp <- 0.1
phi <-0.8
b0<-0.1
b1<-0.1
x[1]<-3.5
# Set the seed, so we can reproduce the results
set.seed(553)
# For-loop that simulates the state through time, using i instead of t,
for (t in 2:N){
  x[t] = b0+phi*x[t-1]+light.l[t]*b1+rnorm(1, 0, sdp)
}


set.seed(50)

y_miss<-list(x,x,x,x,x,x)
#vector of missing number amounts
missing_n_tot<-c(0,25,50,100,150,300)

missing_n_week<-round(missing_n_tot/7)

#Create a list to store missing data integers
y_missing_integers<-c()

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-which(is.na(y_miss[[1]]))

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n_week)){
  h<-which(x %in% sample(x,(missing_n_week[i]-missing_n_week[i-1]), replace = FALSE))
  y_missing_integers[[i]]<-c(h,y_missing_integers[[i-1]])
}


for(i in 2:length(missing_n_week)){
  q<-y_missing_integers[[i]]-3
  w<-y_missing_integers[[i]]-2
  e<-y_missing_integers[[i]]-1
  t<-y_missing_integers[[i]]+1
  y<-y_missing_integers[[i]]+2
  u<-y_missing_integers[[i]]+3
  y_missing_integers[[i]]<-c(y_missing_integers[[i]],q,w,e,t,y,u)
}

##Remove last value from indexes 6-8. Unique to this random seed and weeks.
#Accidentally added a missing value to the end because it picked a value close to the end



#Assign NAs to the missing data in each list
for(i in 1:length(y_missing_integers)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  #z[1]<-x[1]
  y_miss[[i]]<-z
}

y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR LIST OF VECTORS
y_index_mis <- lapply(y_miss,function(var){which(is.na(var))}) # Identify the rows for each variable in airquality with NA
y_index_obs <- lapply(y_miss,function(var){which(!is.na(var))}) # Identify the rows for each variable in airquality with observed data
y_nMiss <- lapply(y_index_mis,function(var){length(var)}) # How many NAs?
y_nObs <- lapply(y_index_obs,function(var){length(var)}) # How many NAs?


##Replace NAs with arbitrary number to make Stan happy
for(i in 1:length(missing_n_week)){
  r<-y_miss[[i]]
  r[y_missing_integers[[i]]]<--100 #arbitrary number
  r[1]<-x[1]
  y_miss[[i]]<-r
} 
y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]

my_data <- as_tibble(fit_summary)
y_est_data<-my_data %>% slice(1:length(y_index_mis[[6]]))

##Create object with observed data
date<-1:N
y_obs_data<-as.data.frame(cbind(date[y_index_mis[[6]]],x[y_index_mis[[6]]]))
colnames(y_obs_data)<-c("date","y")
#y_obs_data$date<-as.Date(y_obs_data$date, origin = "1969-12-30")
#x_data<-summary(fit_extract$x, probs=c(0.05,.5,.95))
##Merge observed and estimated

y_combined<-cbind(y_obs_data,y_est_data)

##rename column names for clarity

colnames(y_combined)<-c("date", "observed", "estimated", "se_mean_est", "sd_est", "low", "median","high", "n_eff", "rhat")

##check that column names are correct



##Plot observed and estimated direct comparison
ggplot(data=y_combined, aes(x=observed, y=estimated))+
  geom_point( size=3)+
  geom_abline(intercept=0, slope=1)+
  theme_classic()+
  geom_errorbar(aes(ymin=low, ymax=high))+
  theme(legend.position="top")+
  ylab("Estimated GPP (95% CI)")+
  xlab("Simulated GPP")+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))

##Plot observed and estimated as time series
raw_data<-as.data.frame(cbind(x,date))

ggplot(data=y_combined, aes(x=date, y=estimated))+
  geom_point(data=raw_data, aes(x=date, y=x, color="gray"), size=3)+
  geom_errorbar(data=y_combined,aes(x=date,ymin=low, ymax=high))+ 
  geom_point(aes(color="red"), size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  scale_color_identity(guide = "legend", name=element_blank(), labels=c("Simulated data", "Imputed data"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())




```

\
\
\
\
\
\


### Bayes parameter-simulated missing weeks
``` {r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}

fit_sim_summary_bayes <- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/summary_sim_week_bayes.RDS")
known.data.sim<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/known_sim_week_bayes.RDS")


ggplot(data=fit_sim_summary_bayes, aes(x=mean, y=prop.missing ))+
  geom_point(aes( color=param, group=param),size=3,position=position_dodge(0.5))+
  theme_classic()+
  geom_errorbar(aes(xmin=min, xmax=high,color=param, group=param), width=0.2, size=0.5,position=position_dodge(0.5))+
  theme(legend.position="top")+
  ylab("Percent of Missing Data")+
  xlab("Parameter Estimate")+
  scale_color_manual(values=c("blue", "green", "darkgray", "black"))+
  scale_x_continuous(limits=c(-.15,0.9))+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  geom_vline(xintercept = known.data.sim$known.data,color=c("blue", "darkgray", "green", "black"))

```


\
\
\
\
\
\


### Missing data in the context of Shatto Ditch and Kalamath datasets
``` {r , echo=FALSE, fig.cap="", fig.show="hold", out.width="50%"}
# SDW time series ---------------------------------------------------------


#Load Data
ts.SDW<-read.csv("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/SDW.ts_with light.csv")
ts.SDW$Year<-as.factor(ts.SDW$year)

##Format date for filling in dates with missing data
ts.SDW$date<-as.Date(ts.SDW$date,format="%m/%d/%Y")

##Remove negative GPP values
ts.SDW<- subset(ts.SDW,GPP >= 0)

##Fill in missing dates
df.SDW<-complete(date = seq.Date(min(ts.SDW$date), max(ts.SDW$date), by="day"), data=ts.SDW)

##Code data to be missing=1 or observed=0
N<-ifelse(is.na(df.SDW$GPP),1,0)

## Calculate length of data gaps
#prepare vectors for loop
x<-NA 
length_miss<-NA
x[1]<-N[1]
length_miss[1]<-1

#loop over data and return the length of gaps
for (i in 2:length(df.SDW$GPP)){
  x[i]<-ifelse(N[i]==1,1+x[i-1], 0) #If data is missing add to yesterdays value by 1. If data observed then 0.
  length_miss[i]<-ifelse(x[i]==0,x[i-1], NA) #Save length of gap on the day data is observed (0) after a gap
  length_miss[i]<-ifelse(length_miss[i]==0,NA,length_miss[i]) #Replace days with observed data with NA
}

## Calculate length of observed data before gap. Same as above but for lengths of observed data
z<-NA
z[1]<-N[1]
length_obs<-NA
for (i in 2:length(df.SDW$GPP)){
  z[i]<-ifelse(N[i]==0,1+z[i-1], 0)
  length_obs[i]<-ifelse(z[i]==0,z[i-1], NA)
  length_obs[i]<-ifelse(length_obs[i]==0,NA,length_obs[i] )
}


## save to full dataset and check that everything is correct
df.SDW$length_obs<-length_obs
df.SDW$length_miss<-length_miss

## estimate negative binomial distribution parameters of missing data length integers
length_miss_parm<-length_miss[complete.cases(length_miss)]


## plot histogram
hist(length_miss_parm, breaks=seq(0,max(length_miss_parm+1),by=1), prob=TRUE, ylim=c(0,0.4),xlim=c(0, 70), xlab="Length of missing data gap",
     #main="Negative binomial distribution with mu=8.6 and size=0.65")
     main="Histogram of missing data gap lengths from Shatto")


# Kalamath River (SV) time series ---------------------------------------------------------


#Load Data
ts.SV<-read.csv("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/params.csv")
ts.SV$year<-(year(ts.SV$date))

##Format date for filling in dates with missing data
ts.SV$date<-as.Date(ts.SV$date,format="%Y-%m-%d")

##Remove negative GPP values
ts.SV<- subset(ts.SV,GPP.daily >= 0)
ts.SV<- subset(ts.SV, year>=2018)
ts.SV$year<-as.factor(year(ts.SV$date))

##Fill in missing dates
df.SV<-complete(date = seq.Date(min(ts.SV$date), max(ts.SV$date), by="day"), data=ts.SV)


##Code data to be missing=1 or observed=0
N<-ifelse(is.na(df.SV$GPP.daily),1,0)

## Calculate length of data gaps
#prepare vectors for loop
x<-NA
length_miss<-NA
x[1]<-N[1]
length_miss[1]<-1

#loop over data and return the length of gaps
for (i in 2:length(df.SV$GPP.daily)){
  x[i]<-ifelse(N[i]==1,1+x[i-1], 0) #If data is missing add to yesterdays value by 1. If data observed then 0.
  length_miss[i]<-ifelse(x[i]==0,x[i-1], NA) #Save length of gap on the day data is observed (0) after a gap
  length_miss[i]<-ifelse(length_miss[i]==0,NA,length_miss[i]) #Replace days with observed data with NA
}

## Calculate length of observed data before gap. Same as above but for lengths of observed data
z<-NA
z[1]<-N[1]
length_obs<-NA
for (i in 2:length(df.SV$GPP.daily)){
  z[i]<-ifelse(N[i]==0,1+z[i-1], 0)
  length_obs[i]<-ifelse(z[i]==0,z[i-1], NA)
  length_obs[i]<-ifelse(length_obs[i]==0,NA,length_obs[i] )
}


## save to full dataset and check that everything is correct
df.SV$length_obs<-length_obs
df.SV$length_miss<-length_miss

length_miss_parm<-length_miss[complete.cases(length_miss)]

hist(length_miss_parm, breaks=seq(0,max(length_miss_parm+1),by=1), prob=TRUE, ylim=c(0,0.7), xlab="Length of missing data gap",
     #main="Negative binomial distribution with mu=8.6 and size=0.65")
     main="Histogram of missing data gap lengths from SV")

miss.perc.SD<-40.1
miss.perc.SV<-round(length(which(is.na(df.SV$GPP.daily), TRUE))/length(df.SV$GPP.daily)*100, digits=1)
miss.mean.length.SD<-round(mean(df.SDW$length_miss, na.rm = TRUE), 1)
miss.sd.length.SD<-round(sd(df.SDW$length_miss, na.rm = TRUE),1)
miss.mean.length.SV<-round(mean(df.SV$length_miss, na.rm = TRUE),1)
miss.sd.length.SV<-round(sd(df.SV$length_miss, na.rm = TRUE),1)

site<-rbind("Shatto", "SV")
years<-rbind(10,3)
perc<-rbind(miss.perc.SD,miss.perc.SV)
avg<-rbind(miss.mean.length.SD,miss.mean.length.SV)
std<-rbind(miss.sd.length.SD,miss.sd.length.SV)

total<-cbind(site, years, perc, avg, std)


knitr::kable(total[,1:5],col.names=(c("Site", "Years of data","Missing data (%)", "Average length (d)", "St. dev (d)")),row.names = FALSE)

```
\
\
\
\
\


### Missing data in the context of Appling et al. dataset
I filled in the dates with missing data in the Appling et al. paper by site $\cdot$ year and made a historgram of missing data frequencies. I am making the assumption that if data were measured at the beginning and end of the year then they were likley collecting data for the whole year. There are obviously flaws to that assumption but it was the easiest way to address whether data was missing because it was actively being collected or not. The `r colorize("red line", "red")` is the percent of missing data for entire 10 year Shatto Ditch dataset. The `r colorize("blue line", "blue")` is the percent of missing data from 2 years of Kalamath River dataset (from Laurel).

``````{r , echo=FALSE, fig.cap="", fig.show="hold", out.width="75%"}
# Find sites --------------------------------------------------------------

###Count NAs
cdata <- ddply(sp, c("site_name", "year"), summarize,
               N    = length(GPP),
               N.miss= sum(is.na(GPP)),
               Prop.miss=round(sum(is.na(GPP))/length(GPP)*100))


##Find sites with low missing data
full.year<-subset(cdata, N==365)

###Summary of NAs               
#Histogram
hist(full.year$Prop.miss, main="Distribution of percent missing data from Appling et al. site*years", xlab="Percent missing data")
abline(v=40.1, col="red")
abline(v=3.7, col="blue")

#summary stats
summary(full.year$Prop.miss)
```


Next, I searched the Appling et al dataset for the site $\cdot$ year(s) with least amount of missing data. There was not a site $\cdot$ year combination with a full year of data, but there were two with less than 3% of data missing. 

```{r echo=FALSE, results='asis'}
##Find sites with low missing data
low.miss<-cdata[which(cdata$N==365 & cdata$Prop.miss<4),]


cols<-c(1:2,4:5)
knitr::kable(low.miss[,cols],col.names=(c("Site", "Year","Missing data (count)", "Prop. of year missing")),row.names = FALSE)
```

Fortunately, they each have somewhat unique annual GPP trends.

```{r figures-side, echo=FALSE,results='hide',fig.keep='all', fig.cap="", fig.show="hold", out.width="50%"}

low.miss.1<-subset(sp, site_name==low.miss$site_name[1] & year==2016)
low.miss.2<-subset(sp, site_name==low.miss$site_name[2] & year==2016)

##Simulate light for each site
hms<-rep("12:00:00", times=length(low.miss.1$date))
low.miss.1$date<-as.POSIXct(paste(low.miss.1$date.f, hms),tryFormats = c("%Y-%m-%d %H:%M:%OS"))
low.miss.2$date<-as.POSIXct(paste(low.miss.2$date.f, hms),tryFormats = c("%Y-%m-%d %H:%M:%OS"))

##light
# From Yard et al. (1995) Ecological Modelling.  Remember your trig?  
# calculate light as umol photon m-2 s-1.
# Arguments are:  
# time = a date and time input (posixct object)
# lat = latitude of field site
# longobs = longitude of field site
# longstd = standard longitude of the field site (NOTE: watch daylight savings time!!!). For PST, longstd is be 120 degrees. But during PDT it is 105 degrees. MST is 105 deg. MDT is 90. 


# convert degrees to radians
radi<-function(degrees){(degrees*pi/180)}

# function to estimate light
lightest<- function (time, lat, longobs, longstd) {
  jday<-yday(time)
  E<- 9.87*sin(radi((720*(jday-81))/365)) - 7.53*cos(radi((360*(jday-81))/365)) - 1.5*sin(radi((360*(jday-81))/365))
  LST<-as.numeric(time-trunc(time))
  ST<-LST+(3.989/1440)*(longstd-longobs)+E/1440
  solardel<- 23.439*sin(radi(360*((283+jday)/365)))
  hourangle<-(0.5-ST)*360
  theta<- acos( sin(radi(solardel)) * sin(radi(lat)) + cos(radi(solardel)) * cos(radi(lat)) * cos(radi(hourangle)) )
  suncos<-ifelse(cos(theta)<0, 0, cos(theta))
  GI<- suncos*2326
  GI	
  
}
low.miss.1$sim.light<-lightest(time=low.miss.1$date, lat=sd$lat[sd$site_name==low.miss$site_name[1]], longobs=sd$lon[sd$site_name==low.miss$site_name[1]],longstd=75)
low.miss.2$sim.light<-lightest(time=low.miss.2$date, lat=sd$lat[sd$site_name==low.miss$site_name[2]], longobs=sd$lon[sd$site_name==low.miss$site_name[2]],longstd=75) 


##Impute missing covariates for prediction
#save location of missing data

lowmiss1_missing_integers<-which(is.na(low.miss.1$GPP))
lowmiss2_missing_integers<-which(is.na(low.miss.2$GPP))

#Do multiple imputations and save shortwave light and discharge  
lowmiss1<-as.data.frame(cbind(low.miss.1$GPP,low.miss.1$temp.water,low.miss.1$discharge, low.miss.1$shortwave,low.miss.1$date.f))
colnames(lowmiss1)<-c("GPP", "temp","q","meas.light", "ts")
z2<-amelia( lowmiss1, m = 5, p2s=1, ts="ts", lags="GPP", bounds=rbind(c(1,0,Inf)))
i1<-z2$imputations$imp1
i2<-z2$imputations$imp2
i3<-z2$imputations$imp3
i4<-z2$imputations$imp4
i5<-z2$imputations$imp5
arr <- abind(i1,i2,i3,i4,i5, along = 3)
z3<-as.data.frame(rowMeans(arr, dims = 2))
low.miss.1$imp.shortwave<-z3$meas.light
low.miss.1$imp.discharge<-z3$q

lowmiss2<-as.data.frame(cbind(low.miss.2$GPP,low.miss.2$temp.water,low.miss.2$discharge, low.miss.2$shortwave,low.miss.2$date.f))
colnames(lowmiss2)<-c("GPP", "temp","q","meas.light", "ts")
z2<-amelia( lowmiss2, m = 5, p2s=1, ts="ts", lags="GPP", bounds=rbind(c(1,0,Inf)))
i1<-z2$imputations$imp1
i2<-z2$imputations$imp2
i3<-z2$imputations$imp3
i4<-z2$imputations$imp4
i5<-z2$imputations$imp5
arr <- abind(i1,i2,i3,i4,i5, along = 3)
z3<-as.data.frame(rowMeans(arr, dims = 2))
low.miss.2$imp.shortwave<-z3$meas.light
low.miss.2$imp.discharge<-z3$q


par(mar=c(4,4,.1,.1))
###Plot site data and light

main1<-sd$long_name[sd$site_name==low.miss$site_name[1]]
year1<-sd$long_name[sd$site_name==low.miss$year[1]]
main2<-sd$long_name[sd$site_name==low.miss$site_name[2]]
ggplot(data=low.miss.1, aes(x=date, y=GPP))+
  geom_point(color="black", size=3)+
  geom_errorbar(aes(x=date,ymin=GPP.lower, ymax=GPP.upper), width=0.2, size=0.5)+
  geom_line(aes(x=date, y=imp.shortwave/100), color="orange")+
  geom_line(aes(x=date, y=imp.discharge/10), color="blue")+
  theme(legend.position="top")+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("GPP")+
  xlab("Time (days)")+
  ylim(c(0,7))+
  ggtitle(paste0(sd$long_name[sd$site_name==low.miss$site_name[1]],"-"," ", 2016))+
  annotate(geom="text", x=low.miss.1$date[300],
  y=6,label=paste(low.miss$Prop.miss[1],"% of data missing"),color="red")                 

ggplot(data=low.miss.2, aes(x=date, y=GPP))+
  geom_point(color="black", size=3)+
  geom_errorbar(aes(x=date,ymin=GPP.lower, ymax=GPP.upper), width=0.2, size=0.5)+
  geom_line(aes(x=date, y=imp.shortwave/100), color="orange")+
  geom_line(aes(x=date, y=imp.discharge/3), color="blue")+
  theme(legend.position="top")+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(legend.position="top")+
  ylab("GPP")+
  xlab("Time (days)")+
  ylim(c(0,7))+
  ggtitle(paste0(sd$long_name[sd$site_name==low.miss$site_name[2]],"-"," ", 2016))+
  annotate(geom="text", x=low.miss.2$date[300],
  y=6,label=paste(low.miss$Prop.miss[2],"% of data missing"),color="red")  

```
\
\
\
\
\


### Estimating missing data on real datasets--Bayesian parameter estimation
I randomly removed data in 7-day blocks ranging from 2 to 60% of the original data.
```{r include=FALSE}
##Force some missing data-BY WEEK##
#Note-the model will still work if no data is missing but the objects in the next block of code (i.e., "y_index_mis", etc.)
#still need to be created
set.seed(50)
x<-low.miss.1$GPP
y_miss<-list(x,x,x,x,x,x)
#vector of missing number amounts
missing_n_tot<-c(0,25,50,100,150,300)

missing_n_week<-round(missing_n_tot/7)

#Create a list to store missing data integers
y_missing_integers<-c()

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-which(is.na(y_miss[[1]]))

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n_week)){
  h<-which(x %in% sample(x,(missing_n_week[i]-missing_n_week[i-1]), replace = FALSE))
  y_missing_integers[[i]]<-c(h,y_missing_integers[[i-1]])
}


for(i in 2:length(missing_n_week)){
  q<-y_missing_integers[[i]]-3
  w<-y_missing_integers[[i]]-2
  e<-y_missing_integers[[i]]-1
  t<-y_missing_integers[[i]]+1
  y<-y_missing_integers[[i]]+2
  u<-y_missing_integers[[i]]+3
  y_missing_integers[[i]]<-c(y_missing_integers[[i]],q,w,e,t,y,u)
}

##Remove last value from indexes 6-8. Unique to this random seed and weeks.
#Accidentally added a missing value to the end because it picked a value close to the end



#Assign NAs to the missing data in each list
for(i in 1:length(y_missing_integers)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  #z[1]<-x[1]
  y_miss[[i]]<-z
}

y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]

summary(y_miss)

miss<-sapply(y_miss, function(x) sum(length(which(is.na(x)))))
prop.miss<-round(miss/length(x)*100)
prop.miss

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR SINGLE VECTOR
#y_index_mis <- which(is.na(y_miss)) # Identify the rows for each variable in airquality with NA
#y_index_obs <- which(!is.na(y_miss)) # Identify the rows for each variable in airquality with observed data
#y_nMiss <- length(y_index_mis)# How many NAs?
#y_nObs <- length(y_index_obs) # How many NAs?

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR LIST OF VECTORS
y_index_mis <- lapply(y_miss,function(var){which(is.na(var))}) # Identify the rows for each variable in airquality with NA
y_index_obs <- lapply(y_miss,function(var){which(!is.na(var))}) # Identify the rows for each variable in airquality with observed data
y_nMiss <- lapply(y_index_mis,function(var){length(var)}) # How many NAs?
y_nObs <- lapply(y_index_obs,function(var){length(var)}) # How many NAs?


##Replace NAs with arbitrary number to make Stan happy
for(i in 1:length(missing_n_week)){
  r<-y_miss[[i]]
  r[y_missing_integers[[i]]]<--100 #arbitrary number
  r[1]<-x[1]
  y_miss[[i]]<-r
} 
y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]
summary(y_miss)

```
\
\
\
\
\


### Bayes estimated data-Tenn
```{r,echo=FALSE,fig.cap="", fig.show="hold", out.width="50%" }
#setwd("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions")
##Force some missing data-BY WEEK##
#Note-the model will still work if no data is missing but the objects in the next block of code (i.e., "y_index_mis", etc.)
#still need to be created
set.seed(50)
x<-low.miss.1$GPP
y_miss<-list(x,x,x,x,x,x)
#vector of missing number amounts
missing_n_tot<-c(0,25,50,100,150,300)

missing_n_week<-round(missing_n_tot/7)

#Create a list to store missing data integers
y_missing_integers<-c()

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-which(is.na(y_miss[[1]]))

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n_week)){
  h<-which(x %in% sample(x,(missing_n_week[i]-missing_n_week[i-1]), replace = FALSE))
  y_missing_integers[[i]]<-c(h,y_missing_integers[[i-1]])
}


for(i in 2:length(missing_n_week)){
  q<-y_missing_integers[[i]]-3
  w<-y_missing_integers[[i]]-2
  e<-y_missing_integers[[i]]-1
  t<-y_missing_integers[[i]]+1
  y<-y_missing_integers[[i]]+2
  u<-y_missing_integers[[i]]+3
  y_missing_integers[[i]]<-c(y_missing_integers[[i]],q,w,e,t,y,u)
}

##Remove last value from indexes 6-8. Unique to this random seed and weeks.
#Accidentally added a missing value to the end because it picked a value close to the end



#Assign NAs to the missing data in each list
for(i in 1:length(y_missing_integers)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  #z[1]<-x[1]
  y_miss[[i]]<-z
}

y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]

#summary(y_miss)

miss<-sapply(y_miss, function(x) sum(length(which(is.na(x)))))
prop.miss<-round(miss/length(x)*100)
#prop.miss

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR SINGLE VECTOR
#y_index_mis <- which(is.na(y_miss)) # Identify the rows for each variable in airquality with NA
#y_index_obs <- which(!is.na(y_miss)) # Identify the rows for each variable in airquality with observed data
#y_nMiss <- length(y_index_mis)# How many NAs?
#y_nObs <- length(y_index_obs) # How many NAs?

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR LIST OF VECTORS
y_index_mis <- lapply(y_miss,function(var){which(is.na(var))}) # Identify the rows for each variable in airquality with NA
y_index_obs <- lapply(y_miss,function(var){which(!is.na(var))}) # Identify the rows for each variable in airquality with observed data
y_nMiss <- lapply(y_index_mis,function(var){length(var)}) # How many NAs?
y_nObs <- lapply(y_index_obs,function(var){length(var)}) # How many NAs?


##Replace NAs with arbitrary number to make Stan happy
for(i in 1:length(missing_n_week)){
  r<-y_miss[[i]]
  r[y_missing_integers[[i]]]<--100 #arbitrary number
  r[1]<-x[1]
  y_miss[[i]]<-r
} 
y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]
#summary(y_miss)



##Create object with estimated data
fit.miss<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/full_bayes_lowmiss1.RDS")
fit_summary_bayes_data<-(summary(fit.miss[[6]], probs=c(0.025,.5,.975))$summary)
my_data <- as_tibble(fit_summary_bayes_data)
y_est_data<-my_data %>% slice(1:length(y_index_mis[[6]]))

##Create object with observed data
date<-1:length(y_miss[[6]])
y_obs_data<-as.data.frame(cbind(date[y_index_mis[[6]]],low.miss.2$GPP[y_index_mis[[6]]]))
colnames(y_obs_data)<-c("date","y") 
#y_obs_data$date<-as.Date(y_obs_data$date, origin = "1969-12-30")
#x_data<-summary(fit_extract$x, probs=c(0.05,.5,.95))
##Merge observed and estimated

y_combined<-cbind(y_obs_data,y_est_data)

##rename column names for clarity

colnames(y_combined)<-c("date", "observed", "estimated", "se_mean_est", "sd_est", "low", "median","high", "n_eff", "rhat")

##check that column names are correct

#head(y_combined)

##Plot observed and estimated direct comparison
ggplot(data=y_combined, aes(x=observed, y=estimated))+
  geom_point( size=3)+
  geom_abline(intercept=0, slope=1)+
  theme_classic()+
  geom_errorbar(aes(ymin=low, ymax=high))+
  theme(legend.position="top")+
  ylab("Estimated GPP (95% CI)")+
  xlab("Observed GPP")+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))


raw_data<-as.data.frame(cbind(low.miss.1$GPP,date))

ggplot(data=y_combined, aes(x=date, y=estimated))+
  geom_errorbar(data=y_combined,aes(x=date,ymin=low, ymax=high))+ 
  geom_point(aes(color="red"), size=3)+
  geom_point(data=raw_data, aes(x=date, y=x, color="gray"), size=3)+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  scale_color_identity(guide = "legend", name=element_blank(), labels=c("Simulated data", "Imputed data"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())


```


\
\
\
\
\


### Bayes parameter-Tenn
```{r bayes-param-compare, echo=FALSE, fig.cap="", fig.show="hold", out.width="50%"}

#setwd("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions")
fit_summary_bayes <- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/summary_bayes_lowmiss1.RDS")
known.data<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/known_data_bayes_lowmiss1.RDS")


##Plot parameters
ggplot(data=fit_summary_bayes, aes(x=mean, y=prop.missing ))+
  geom_point(aes( color=param, group=param),size=3,position=position_dodge(0.5))+
  theme_classic()+
  geom_errorbar(aes(xmin=min, xmax=high,color=param, group=param), width=0.2, size=0.5,position=position_dodge(0.5))+
  theme(legend.position="top")+
  ylab("Percent of Missing Data")+
  xlab("Parameter Estimate")+
  scale_color_manual(values=c("blue", "green", "darkgray", "black"))+
  scale_x_continuous(limits=c(-5,1))+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  geom_vline(xintercept = known.data,color=c("black", "darkgray", "green", "blue"))

##Plot parameters
ggplot(data=fit_summary_bayes, aes(x=mean, y=prop.missing ))+
  geom_point(aes( color=param, group=param),size=3,position=position_dodge(0.5))+
  theme_classic()+
  geom_errorbar(aes(xmin=min, xmax=high,color=param, group=param), width=0.2, size=0.5,position=position_dodge(0.5))+
  theme(legend.position="top")+
  ylab("Percent of Missing Data")+
  xlab("Parameter Estimate")+
  scale_color_manual(values=c("blue", "green", "darkgray", "black"))+
  scale_x_continuous(limits=c(0,1))+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),)+
  geom_vline(xintercept = known.data,color=c("black", "darkgray", "green", "blue"))
```






```{r, echo=FALSE}
##Force some missing data-BY WEEK##
#Note-the model will still work if no data is missing but the objects in the next block of code (i.e., "y_index_mis", etc.)
#still need to be created
set.seed(50)
x<-low.miss.2$GPP
y_miss<-list(x,x,x,x,x,x)
#vector of missing number amounts
missing_n_tot<-c(0,25,50,100,150,300)

missing_n_week<-round(missing_n_tot/7)

#Create a list to store missing data integers
y_missing_integers<-c()

#Create initial missing data integer set. Then build on with the for loop
y_missing_integers[[1]]<-which(is.na(y_miss[[1]]))

#Adds the previous missing data integers to the next set. This makes them nested.
#i.e, all the missing data 10 integers are added to 15 more to make missing data 15.
for(i in 2:length(missing_n_week)){
  h<-which(x %in% sample(x,(missing_n_week[i]-missing_n_week[i-1]), replace = FALSE))
  y_missing_integers[[i]]<-c(h,y_missing_integers[[i-1]])
}


for(i in 2:length(missing_n_week)){
  q<-y_missing_integers[[i]]-3
  w<-y_missing_integers[[i]]-2
  e<-y_missing_integers[[i]]-1
  t<-y_missing_integers[[i]]+1
  y<-y_missing_integers[[i]]+2
  u<-y_missing_integers[[i]]+3
  y_missing_integers[[i]]<-c(y_missing_integers[[i]],q,w,e,t,y,u)
}

##Remove last value from indexes 6-8. Unique to this random seed and weeks.
#Accidentally added a missing value to the end because it picked a value close to the end



#Assign NAs to the missing data in each list
for(i in 1:length(y_missing_integers)){
  z<-y_miss[[i]]
  z[y_missing_integers[[i]]]<-NA
  #z[1]<-x[1]
  y_miss[[i]]<-z
}

y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]

#summary(y_miss)

miss<-sapply(y_miss, function(x) sum(length(which(is.na(x)))))
prop.miss<-round(miss/length(x)*100)
#prop.miss

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR SINGLE VECTOR
#y_index_mis <- which(is.na(y_miss)) # Identify the rows for each variable in airquality with NA
#y_index_obs <- which(!is.na(y_miss)) # Identify the rows for each variable in airquality with observed data
#y_nMiss <- length(y_index_mis)# How many NAs?
#y_nObs <- length(y_index_obs) # How many NAs?

##Create objects with the location (index) of missing or observed data AND number
## of missing or observed data
#FOR LIST OF VECTORS
y_index_mis <- lapply(y_miss,function(var){which(is.na(var))}) # Identify the rows for each variable in airquality with NA
y_index_obs <- lapply(y_miss,function(var){which(!is.na(var))}) # Identify the rows for each variable in airquality with observed data
y_nMiss <- lapply(y_index_mis,function(var){length(var)}) # How many NAs?
y_nObs <- lapply(y_index_obs,function(var){length(var)}) # How many NAs?


##Replace NAs with arbitrary number to make Stan happy
for(i in 1:length(missing_n_week)){
  r<-y_miss[[i]]
  r[y_missing_integers[[i]]]<--100 #arbitrary number
  r[1]<-x[1]
  y_miss[[i]]<-r
} 
y_miss[[6]]<-y_miss[[6]][1:length(y_miss[[6]])-1]
#summary(y_miss)

```
\
\
\
\
\


### Bayes estimated data-MI
```{r,echo=FALSE,fig.cap="", fig.show="hold", out.width="50%" }
#setwd("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions")
fit.miss<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/full_bayes_lowmiss2.RDS")
##Create object with estimated data
fit_summary_bayes_data<-(summary(fit.miss[[6]], probs=c(0.025,.5,.975))$summary)
my_data <- as_tibble(fit_summary_bayes_data)
y_est_data<-my_data %>% slice(1:length(y_index_mis[[6]]))

##Create object with observed data
date<-1:length(y_miss[[6]])
y_obs_data<-as.data.frame(cbind(date[y_index_mis[[6]]],low.miss.2$GPP[y_index_mis[[6]]]))
colnames(y_obs_data)<-c("date","y") 
#y_obs_data$date<-as.Date(y_obs_data$date, origin = "1969-12-30")
#x_data<-summary(fit_extract$x, probs=c(0.05,.5,.95))
##Merge observed and estimated

y_combined<-cbind(y_obs_data,y_est_data)

##rename column names for clarity

colnames(y_combined)<-c("date", "observed", "estimated", "se_mean_est", "sd_est", "low", "median","high", "n_eff", "rhat")

##check that column names are correct

#head(y_combined)

##Plot observed and estimated direct comparison
ggplot(data=y_combined, aes(x=observed, y=estimated))+
  geom_point( size=3)+
  geom_abline(intercept=0, slope=1)+
  theme_classic()+
  geom_errorbar(aes(ymin=low, ymax=high))+
  theme(legend.position="top")+
  ylab("Estimated GPP (95% CI)")+
  xlab("Observed GPP")+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))


raw_data<-as.data.frame(cbind(low.miss.2$GPP,date))

ggplot(data=y_combined, aes(x=date, y=estimated))+
  geom_errorbar(data=y_combined,aes(x=date,ymin=low, ymax=high))+
  geom_point(aes(color="red"), size=3)+
  geom_point(data=raw_data, aes(x=date, y=x, color="gray"), size=3)+
  theme_classic()+
  theme_classic()+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  scale_color_identity(guide = "legend", name=element_blank(), labels=c("Simulated data", "Imputed data"))+
  theme(legend.position="top")+
  ylab("Data")+
  xlab("Time")+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())


```


\
\
\
\
\


### Bayes parameter-MI
```{r , echo=FALSE, fig.cap=" ", fig.show="hold", out.width="50%"}
#setwd("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions")
#fit.miss<- readRDS("full_bayes_lowmiss2.RDS")
fit_summary_bayes <- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/summary_bayes_lowmiss2.RDS")
known.data<- readRDS("C:/Users/matt/IDrive-Sync/Postdoc/Estimating missing data/daily_predictions/known_data_bayes_lowmiss2.RDS")


##Plot parameters
ggplot(data=fit_summary_bayes, aes(x=mean, y=prop.missing ))+
  geom_point(aes( color=param, group=param),size=3,position=position_dodge(0.5))+
  theme_classic()+
  geom_errorbar(aes(xmin=min, xmax=high,color=param, group=param), width=0.2, size=0.5,position=position_dodge(0.5))+
  theme(legend.position="top")+
  ylab("Percent of Missing Data")+
  xlab("Parameter Estimate")+
  scale_color_manual(values=c("blue", "green", "darkgray", "black"))+
  scale_x_continuous(limits=c(-12,1.8))+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  geom_vline(xintercept = known.data,color=c("black", "darkgray", "green", "blue"))

##Plot parameters
ggplot(data=fit_summary_bayes, aes(x=mean, y=prop.missing ))+
  geom_point(aes( color=param, group=param),size=3,position=position_dodge(0.5))+
  theme_classic()+
  geom_errorbar(aes(xmin=min, xmax=high,color=param, group=param), width=0.2, size=0.5,position=position_dodge(0.5))+
  theme(legend.position="top")+
  ylab("Percent of Missing Data")+
  xlab("Parameter Estimate")+
  scale_color_manual(values=c("blue", "green", "darkgray", "black"))+
  scale_x_continuous(limits=c(0,1.8))+
  theme(axis.title.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y=element_text(size=18,colour = "black"))+
  theme(axis.text.y=element_text(size=18,colour = "black"))+
  theme(axis.text.x=element_text(size=18,colour = "black"))+
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),)+
  geom_vline(xintercept = known.data,color=c("black", "darkgray", "green", "blue"))
```


