---
title: "AR algebra"
output: html_document
date: "2023-05-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load packages
library(tidyverse)
library(rstan)
```

## AR Time Series

A cheat sheet for simulating autoregressive time series data and recovering parameters using a Stan model.

### AR algebra

A basic first order autoregressive model (AR1) takes the following form:

$$ y_t = \phi y_{t-1} + \epsilon_t $$
Where $\epsilon_t$ is a time series of random innovations centered at zero with a standard deviation of $\sigma$.

Example code to simulate data for an AR1 model:

```{r}

n <- 100     # number of observations 
phi <- 0.8   # AR1 coefficient
sigma <- 1   # sd of random innovations

# declare an empty vector and initialize the first timestep
y <- vector('numeric', length = n)
y[1] <- 0

# complete the AR process
for(t in 2:n){
    y[t] <- phi * y[t-1] + rnorm(1, 0, sigma)
}

plot(y, type = 'l') 

```

If we have a time series with a non-zero mean that can be described as a function of external drivers, $X$, generated by time series to have a mean other than zero, unction for removing data # makeMissing() source("Functions/missing_data_functions.R")   # Simulate data # simulate arima process set.seed(100) n <- 365 p <- 2 phi <- runif(1, 0, 0.8) ###phi gets weird too close to 1 ### beta <- rnorm(p + 1) X <- rand_mod_matrix(n = n, p = p) sde <- 1 phi = 0.8


beta <- c( 5, 1, 3)
mu <- as.double(X %*% beta)


y1 <- arima.sim(
   n = n,
   model = list(ar = phi),
   sd = sde) + mu

mean(y1)

x <- rep(mean(mu), n)
for(i in 2:n){
  x[i] = phi*(x[i-1] - mu[i-1]) + mu[i] + rnorm(1, 0, 1)
}
mean(x)
y2 <- rep(mean(mu), n)

for(i in 2:n){
    y2[i] <- phi * y2[i-1] +  rnorm(1, 0, sde)
}

y2 = y2 + mu
#### Parameter recovery using arima and brms
phi; beta; sde
arima(y1, order = c(1,0,0), xreg = X[,-1])
arima(y2, order = c(1,0,0), xreg = X[,-1])
arima(x, order = c(1,0,0), xreg = X[,-1])

dat1 <- data.frame(y = y1, 
                   x1 = X[,2],
                   x2 = X[,3])

dat2 <- data.frame(y = y2, 
                   x1 = X[,2],
                   x2 = X[,3])
bform <- brms::bf(y ~ x1 + x2 + ar(p = 1))
bmod1 <- brms::brm(bform, data = dat1)
bmod2 <- brms::brm(bform, data = dat2)

bmod
bmod2

# brms::posterior_interval(bmod)

#### Comparison to data augmentation in STAN ###

datlist1 <- list(N = n,
                P_obs = y1, 
                light = X[,2],
                discharge = X[,3])
datlist2 <- list(N = n,
                P_obs = x, 
                light = X[,2],
                discharge = X[,3])

ar_fit1 <- stan('GPP sim and real/Stan_code/AR1.stan',
                data = datlist1,
                chains = 4,
                iter = 4000)

ar_fit2 <- stan('GPP sim and real/Stan_code/AR1.stan',
                data = datlist2,
                chains = 4,
                iter = 4000)

print(ar_fit1, pars = c('phi', 'beta', 'sigma'))
print(ar_fit2, pars = c('phi', 'beta', 'sigma'))
print(arp_fit, pars = c('phi', 'beta', 'sigma'))

###################################################################
# Create data list for feeding into Stan code:
# Generate vectors with indicies of observed and missing data points ##
# subset GPP timeseries to the observations only ##
stan_datasim <- lapply(simmissingdf, function(x) {
    ii_obs <- which(!is.na(x$GPP))
    ii_mis <- which(is.na(x$GPP))
    simdat <- list(
      N_obs = length(ii_obs),   # number of observations
      N_mis = length(ii_mis),   # number of missing data points
      ii_obs = ii_obs,          # indices of observations
      ii_mis = ii_mis,          # indices of missing observations
      P_obs = x$GPP[ii_obs],    # vector of observations
      light = x$light, discharge = x$discharge)
      
    return(simdat)
  })

#### Model Fit ####

# Stan settings
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

# Fit models
x <- stan_datasim[[1]]
X <- data.frame(cbind(GPP_sim_MAR$y$propMissAct_0.5, GPP_sim_MAR$sim_params$X[,-1]))
colnames(X) <- c('GPP', 'light', 'discharge')


y_est <- brms::posterior_samples(bmod) %>%
  summarize(across(everything(), mean)) %>%
  select(starts_with('Ymi')) %>%
  t() %>% as.vector()

data.frame( GPP = stan_datasim[[1]]$P_obs, 
            missing = rep(0, 365),
            y_est = y_est)
plot(seq(1:365), stan_datasim[[1]]$P_obs, type = 'l')
points(which(is.na(X$GPP)), y_est)
plot(stan_datasim[[1]]$P_obs[which(is.na(X$GPP))], y_est)
abline(0,1)
fixef(bmod)

ar1_fit_centered <- stan('GPP sim and real/Stan_code/AR1_centered.stan',
                         data = list(N = x$N_obs, P_obs = x$P_obs,
                                     light = x$light, discharge = x$discharge),
                         chains = 4,
                         iter = 4000, 
                         control = list(max_treedepth = 12),
                         save_warmup = FALSE)
datlist <- list(N = n,
                P = 3, p = 1 ,
                y = y2,
                X = X)
arp_fit <- stan('GPP sim and real/Stan_code/AR-p.stan',
                data = datlist,
                chains = 4,
                iter = 4000,
                # control = list(max_treedepth = 12),
                save_warmup = FALSE)
GPP_sim_MAR$sim_params$phi; GPP_sim_MAR$sim_params$beta

print(ar1_fit, pars = c('phi', 'beta', 'sigma'))
print(ar1_fit_centered, pars = c('phi', 'beta', 'sigma'))
pairs(ar1_fit, pars = c('phi', 'beta', 'sigma'))
pairs(ar1_fit_centered, pars = c('phi', 'beta', 'sigma'))

stan_datasim_fit <- lapply(stan_datasim,
                           function(x) stan("GPP sim and real/Stan_code/AR1_light_Q_centered_2.stan",
                                            data = x,
                                            chains = 4, 
                                            iter = 4000,
                                            control = list(max_treedepth = 12), 
                                            save_warmup=FALSE))
                           fit <- stan("GPP sim and real/Stan_code/AR1_light_Q_centered_2.stan",
                                            data = x,
                                            chains = 4, 
                                            iter = 4000,
                                            control = list(max_treedepth = 12), 
                                            save_warmup=FALSE)

# Ran on server - started 3:27 , finished XXX.

#stan_datasim_fit ## very large list ###


#### pull out SDs as well...###

##Pull param estimates into list ## takes a minute###
fit_summary_pars_bayes <- vector("list",20)
for (i in 1:20){
  fit_summary_pars_bayes[[i]]<-(summary(stan_datasim_fit[[i]], pars=c("beta[1]","beta[2]", "beta[3]", "phi","sdp"), probs=c(0.025,.5,.975))$summary)
}

names(fit_summary_pars_bayes) <- names(GPP_sim_MAR_2)


DAparamdf <- map_df(fit_summary_pars_bayes, ~as.data.frame(.x), .id="missingprop")



############ MISSING NOT AT RANDOM MNAR ##############################

###### Pull out the first in 1000 nested lists for this code ### (Eventually loop over all the lists)

gauss_sim_MNAR_datasets <- readRDS(here("data/Missingdatasets/gauss_sim_minMaxMiss.rds"))

##For nested list of GPP datasets with increasing MNAR data add back in the date column and the covariates## 

GPP_sim_MNAR<- gauss_sim_MNAR_datasets [[1]][["y"]]

GP_sim_MNAR_2<-lapply(=GPP_sim_MNAR,FUN= function(X)cbind.data.frame(GPP=X,days=sim1df$days, light=sim1df$light,discharge =sim1df$discharge))


